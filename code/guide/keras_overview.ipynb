{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.1),\n",
    "             loss=tf.losses.categorical_crossentropy,\n",
    "             metrics=[tf.metrics.categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 6000 samples\n",
      "Epoch 1/5\n",
      "6000/6000 [==============================] - 0s 69us/sample - loss: 11.6844 - categorical_accuracy: 0.1035\n",
      "Epoch 2/5\n",
      "6000/6000 [==============================] - 0s 29us/sample - loss: 11.5205 - categorical_accuracy: 0.1008\n",
      "Epoch 3/5\n",
      "6000/6000 [==============================] - 0s 29us/sample - loss: 11.5224 - categorical_accuracy: 0.0993\n",
      "Epoch 4/5\n",
      "6000/6000 [==============================] - 0s 30us/sample - loss: 11.5230 - categorical_accuracy: 0.0943\n",
      "Epoch 5/5\n",
      "6000/6000 [==============================] - 0s 30us/sample - loss: 11.5212 - categorical_accuracy: 0.1008\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xb27551e10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = np.random.random((6000, 72))\n",
    "train_y = np.random.random((6000, 10))\n",
    "model.fit(train_x, train_y, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 53us/sample - loss: 11.4695 - categorical_accuracy: 0.0950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[11.469466491699219, 0.095]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x = np.random.random((1000, 72))\n",
    "test_y = np.random.random((1000, 10))\n",
    "model.evaluate(test_x, test_y, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 935us/step - loss: 11.4803 - categorical_accuracy: 0.0958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[11.480275122324626, 0.09583333]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = tf.data.Dataset.from_tensor_slices((test_x, test_y))\n",
    "test_data = test_data.batch(32).repeat()\n",
    "model.evaluate(test_data, steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 10),\n",
       " array([[0.10256103, 0.10695486, 0.08855996, ..., 0.10658294, 0.11195687,\n",
       "         0.09660218],\n",
       "        [0.10256103, 0.10695486, 0.08855996, ..., 0.10658294, 0.11195687,\n",
       "         0.09660218],\n",
       "        [0.10256103, 0.10695486, 0.08855996, ..., 0.10658294, 0.11195687,\n",
       "         0.09660218],\n",
       "        ...,\n",
       "        [0.10256103, 0.10695486, 0.08855996, ..., 0.10658294, 0.11195687,\n",
       "         0.09660218],\n",
       "        [0.10256103, 0.10695486, 0.08855996, ..., 0.10658294, 0.11195687,\n",
       "         0.09660218],\n",
       "        [0.10256103, 0.10695486, 0.08855996, ..., 0.10658294, 0.11195687,\n",
       "         0.09660218]], dtype=float32))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model.predict(test_x, batch_size=32)\n",
    "np.shape(result), result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MyModel, self).__init__(name='my_model')\n",
    "        self.num_classes = num_classes\n",
    "        self.layer1 = layers.Dense(32, activation='relu')\n",
    "        self.layer2 = layers.Dense(num_classes, activation='softmax')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        h1 = self.layer1(inputs)\n",
    "        out = self.layer2(h1)\n",
    "        return out\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        shape = tf.TensorShape(input_shape).as_list()\n",
    "        shape[-1] = self.num_classes\n",
    "        return tf.TensorShape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6000 samples\n",
      "Epoch 1/5\n",
      "6000/6000 [==============================] - 0s 54us/sample - loss: 11.5546 - accuracy: 0.0983\n",
      "Epoch 2/5\n",
      "6000/6000 [==============================] - 0s 28us/sample - loss: 11.5138 - accuracy: 0.1105\n",
      "Epoch 3/5\n",
      "6000/6000 [==============================] - 0s 30us/sample - loss: 11.5132 - accuracy: 0.1053\n",
      "Epoch 4/5\n",
      "6000/6000 [==============================] - 0s 31us/sample - loss: 11.5128 - accuracy: 0.1055\n",
      "Epoch 5/5\n",
      "6000/6000 [==============================] - 0s 29us/sample - loss: 11.5126 - accuracy: 0.1063\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xb27a46358>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MyModel(10)\n",
    "model.compile(optimizer=tf.optimizers.RMSprop(0.001),\n",
    "             loss=tf.losses.categorical_crossentropy,\n",
    "             metrics=['accuracy'])\n",
    "model.fit(train_x, train_y, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLayer(layers.Layer):\n",
    "    def __init__(self, out_dim, **kwargs):\n",
    "        self.out_dim = out_dim\n",
    "        super(MyLayer, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        shape = tf.TensorShape((input_shape[1], self.out_dim))\n",
    "        self.kernel = self.add_weight(name='kernel1', shape=shape, \n",
    "                          initializer='uniform', trainable=True)\n",
    "        super(MyLayer, self).build(input_shape)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.kernel)\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        shape = tf.TensorShape(input_shape).as_list()\n",
    "        shape[-1] = self.out_dim\n",
    "        return tf.TensorShape(shape)\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config = super(MyLayer, self).get_config()\n",
    "        base_config['output_dim'] = self.out_dim\n",
    "        return base_config\n",
    "    \n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6000 samples\n",
      "Epoch 1/5\n",
      "6000/6000 [==============================] - 0s 60us/sample - loss: 11.5272 - accuracy: 0.1055\n",
      "Epoch 2/5\n",
      "6000/6000 [==============================] - 0s 47us/sample - loss: 11.5199 - accuracy: 0.1015\n",
      "Epoch 3/5\n",
      "6000/6000 [==============================] - 0s 50us/sample - loss: 11.5166 - accuracy: 0.1087\n",
      "Epoch 4/5\n",
      "6000/6000 [==============================] - 0s 50us/sample - loss: 11.5147 - accuracy: 0.1108\n",
      "Epoch 5/5\n",
      "6000/6000 [==============================] - 0s 51us/sample - loss: 11.5132 - accuracy: 0.1180\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xb271abba8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([MyLayer(10), \n",
    "                             layers.Activation('softmax')])\n",
    "model.compile(optimizer=tf.optimizers.RMSprop(0.001),\n",
    "             loss=tf.losses.categorical_crossentropy,\n",
    "             metrics=['accuracy'])\n",
    "model.fit(train_x, train_y, epochs=5, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6000 samples\n",
      "Epoch 1/5\n",
      "6000/6000 [==============================] - 0s 51us/sample - loss: 11.5128 - accuracy: 0.1202\n",
      "Epoch 2/5\n",
      "6000/6000 [==============================] - 0s 50us/sample - loss: 11.5129 - accuracy: 0.1265\n",
      "Epoch 3/5\n",
      "6000/6000 [==============================] - 0s 52us/sample - loss: 11.5128 - accuracy: 0.1168\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xb28a47ac8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=2, monitor='loss'),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='./logs')\n",
    "]\n",
    "model.fit(train_x, train_y, batch_size=16, epochs=5,\n",
    "         callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6000 samples\n",
      "Epoch 1/5\n",
      "6000/6000 [==============================] - 0s 52us/sample - loss: 11.6139 - accuracy: 0.0993\n",
      "Epoch 2/5\n",
      "6000/6000 [==============================] - 0s 31us/sample - loss: 11.5355 - accuracy: 0.1003\n",
      "Epoch 3/5\n",
      "6000/6000 [==============================] - 0s 30us/sample - loss: 11.5247 - accuracy: 0.1002\n",
      "Epoch 4/5\n",
      "6000/6000 [==============================] - 0s 31us/sample - loss: 11.5179 - accuracy: 0.1057\n",
      "Epoch 5/5\n",
      "6000/6000 [==============================] - 0s 30us/sample - loss: 11.5149 - accuracy: 0.1092\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer=tf.optimizers.Adam(0.001),\n",
    "             loss=tf.losses.categorical_crossentropy,\n",
    "             metrics=['accuracy'])\n",
    "model.fit(train_x, train_y, epochs=5)\n",
    "model.save_weights('./weights/model')\n",
    "model.load_weights('./weights/model')\n",
    "model.save_weights('./weights/weight.h5')\n",
    "model.load_weights('./weights/weight.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pprint\n",
    "json_str = model.to_json()\n",
    "# pprint.pprint(json.loads(json_str))\n",
    "fresh_model = tf.keras.models.model_from_json(json_str)\n",
    "\n",
    "yaml_str = model.to_yaml()\n",
    "# print(yaml_str)\n",
    "fresh_model = tf.keras.models.model_from_yaml(yaml_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6000 samples\n",
      "Epoch 1/5\n",
      "6000/6000 [==============================] - 0s 54us/sample - loss: 11.5194 - accuracy: 0.1013\n",
      "Epoch 2/5\n",
      "6000/6000 [==============================] - 0s 29us/sample - loss: 11.5164 - accuracy: 0.1067\n",
      "Epoch 3/5\n",
      "6000/6000 [==============================] - 0s 29us/sample - loss: 11.5153 - accuracy: 0.1057\n",
      "Epoch 4/5\n",
      "6000/6000 [==============================] - 0s 28us/sample - loss: 11.5147 - accuracy: 0.1072\n",
      "Epoch 5/5\n",
      "6000/6000 [==============================] - 0s 29us/sample - loss: 11.5140 - accuracy: 0.1130\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  layers.Dense(10, activation='softmax', input_shape=(72,)),\n",
    "  layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_x, train_y, batch_size=32, epochs=5)\n",
    "\n",
    "import os\n",
    "os.mkdir('models')\n",
    "model.save('./models/model.h5')\n",
    "fresh_model = tf.keras.models.load_model('./models/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/zd/dj641pks6fsdt5lj4zjp0m4w0000gn/T/tmpy4tegvuw\n",
      "INFO:tensorflow:Using the Keras model provided.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/zd/dj641pks6fsdt5lj4zjp0m4w0000gn/T/tmpy4tegvuw', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0xb286b6fd0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "estimator = tf.keras.estimator.model_to_estimator(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
